// Copyright 2024 Sebastian Eibl
// 
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// 
//     https://www.apache.org/licenses/LICENSE-2.0
// 
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#include "DumpH5MDParallel.hpp"

#include <fmt/format.h>

#include <numeric>

#include "assert/assert.hpp"
#ifdef MRMD_ENABLE_HDF5
#include "hdf5.hpp"
#endif
#include "version.hpp"

namespace mrmd::io
{

#ifdef MRMD_ENABLE_HDF5
namespace impl
{
/**
 * This class collects everything needed for the HDF5 dump. If HDF5 is disabled,
 * this class can be skipped and all HDF5 dependencies are gone.
 */
class DumpH5MDParallelImpl
{
public:
    explicit DumpH5MDParallelImpl(DumpH5MDParallel& config)
        : config_(config)
    {
    }

    void dump(const std::string& filename,
              const data::Subdomain& subdomain,
              const data::Atoms& atoms);

private:
    void updateCache(const data::HostAtoms& atoms);

    void writeHeader(hid_t fileId) const;
    void writeBox(hid_t fileId, const data::Subdomain& subdomain) const;
    {%- for prop in particle %}
    void write{{prop.name | cap_first}}(hid_t fileId, const data::HostAtoms& atoms);
    {%- endfor %}

    template <typename T>
    void writeParallel(hid_t fileId,
                       const std::string& name,
                       const std::vector<hsize_t>& globalDims,
                       const std::vector<hsize_t>& localDims,
                       const std::vector<T>& data);

    DumpH5MDParallel& config_;

    int64_t numLocalParticles = -1;
    int64_t numTotalParticles = -1;
    /// Offset of the local particle chunk in the global particle array.
    int64_t particleOffset = -1;
};

template <typename T>
void DumpH5MDParallelImpl::writeParallel(hid_t fileId,
                                         const std::string& name,
                                         const std::vector<hsize_t>& globalDims,
                                         const std::vector<hsize_t>& localDims,
                                         const std::vector<T>& data)
{
    MRMD_HOST_CHECK_EQUAL(globalDims.size(), localDims.size());
    MRMD_HOST_CHECK_EQUAL(
        data.size(),
        std::accumulate(localDims.begin(), localDims.end(), hsize_t(1), std::multiplies<>()));

    auto dataspace =
        CHECK_HDF5(H5Screate_simple(int_c(globalDims.size()), globalDims.data(), nullptr));
    auto dataset = CHECK_HDF5(H5Dcreate(
        fileId, name.c_str(), typeToHDF5<T>(), dataspace, H5P_DEFAULT, H5P_DEFAULT, H5P_DEFAULT));

    std::vector<hsize_t> offset(globalDims.size(), 0);
    offset[1] = particleOffset;
    std::vector<hsize_t> stride(globalDims.size(), 1);
    std::vector<hsize_t> count(globalDims.size(), 1);
    for (auto i = 0; i < int_c(globalDims.size()); ++i)
    {
        MRMD_HOST_CHECK_LESSEQUAL(
            localDims[i] + offset[i], globalDims[i], fmt::format("i = {}", i));
    }
    auto dstSpace = CHECK_HDF5(H5Dget_space(dataset));
    CHECK_HDF5(H5Sselect_hyperslab(
        dstSpace, H5S_SELECT_SET, offset.data(), stride.data(), count.data(), localDims.data()));

    std::vector<hsize_t> localOffset(globalDims.size(), 0);
    auto srcSpace =
        CHECK_HDF5(H5Screate_simple(int_c(localDims.size()), localDims.data(), nullptr));
    CHECK_HDF5(H5Sselect_hyperslab(srcSpace,
                                   H5S_SELECT_SET,
                                   localOffset.data(),
                                   stride.data(),
                                   count.data(),
                                   localDims.data()));

    auto datawrite = CHECK_HDF5(H5Pcreate(H5P_DATASET_XFER));
    CHECK_HDF5(H5Pset_dxpl_mpio(datawrite, H5FD_MPIO_COLLECTIVE));
    CHECK_HDF5(H5Dwrite(dataset, typeToHDF5<T>(), srcSpace, dstSpace, datawrite, data.data()));

    CHECK_HDF5(H5Pclose(datawrite));
    CHECK_HDF5(H5Sclose(dstSpace));
    CHECK_HDF5(H5Sclose(srcSpace));
    CHECK_HDF5(H5Dclose(dataset));
    CHECK_HDF5(H5Sclose(dataspace));
}

void DumpH5MDParallelImpl::writeHeader(hid_t fileId) const
{
    auto group1 = CHECK_HDF5(H5Gcreate(fileId, "/h5md", H5P_DEFAULT, H5P_DEFAULT, H5P_DEFAULT));
    auto group2 =
        CHECK_HDF5(H5Gcreate(fileId, "/h5md/author", H5P_DEFAULT, H5P_DEFAULT, H5P_DEFAULT));
    auto group3 =
        CHECK_HDF5(H5Gcreate(fileId, "/h5md/creator", H5P_DEFAULT, H5P_DEFAULT, H5P_DEFAULT));
    CHECK_HDF5(H5Gclose(group1));
    CHECK_HDF5(H5Gclose(group2));
    CHECK_HDF5(H5Gclose(group3));

    std::vector<int> data = {1, 1};
    CHECK_HDF5(H5LTset_attribute_int(fileId, "/h5md", "version", data.data(), data.size()));

    CHECK_HDF5(H5LTset_attribute_string(fileId, "/h5md/author", "name", config_.author.c_str()));

    CHECK_HDF5(H5LTset_attribute_string(fileId, "/h5md/creator", "name", PROJECT_NAME.c_str()));
    CHECK_HDF5(H5LTset_attribute_string(fileId, "/h5md/creator", "version", MRMD_VERSION.c_str()));
}

void DumpH5MDParallelImpl::writeBox(hid_t fileId, const data::Subdomain& subdomain) const
{
    std::string groupName = "/particles/" + config_.particleGroupName + "/box";
    auto group =
        CHECK_HDF5(H5Gcreate(fileId, groupName.c_str(), H5P_DEFAULT, H5P_DEFAULT, H5P_DEFAULT));
    std::vector<int> dims = {3};
    CHECK_HDF5(
        H5LTset_attribute_int(fileId, groupName.c_str(), "dimension", dims.data(), dims.size()));

    auto boundaryType = H5Tcopy(H5T_C_S1);
    CHECK_HDF5(H5Tset_size(boundaryType, 8));
    CHECK_HDF5(H5Tset_strpad(boundaryType, H5T_STR_NULLPAD));
    std::vector<hsize_t> boundaryDims = {3};
    auto space = H5Screate_simple(int_c(boundaryDims.size()), boundaryDims.data(), nullptr);
    auto att = H5Acreate(group, "boundary", boundaryType, space, H5P_DEFAULT, H5P_DEFAULT);
    CHECK_HDF5(H5Awrite(att, boundaryType, "periodicperiodicperiodic"));
    CHECK_HDF5(H5Aclose(att));
    CHECK_HDF5(H5Sclose(space));
    CHECK_HDF5(H5Tclose(boundaryType));

    std::string edgesGroupName = groupName + "/edges";
    auto edgesGroup = H5Gcreate(fileId, edgesGroupName.c_str(), H5P_DEFAULT, H5P_DEFAULT, H5P_DEFAULT);
    std::vector<hsize_t> edgesStepDims = {1};
    std::vector<int64_t> step = {0};
    std::string edgesStepDataset = edgesGroupName + "/step";
    CHECK_HDF5(H5LTmake_dataset(
        fileId, edgesStepDataset.c_str(), 1, edgesStepDims.data(), typeToHDF5<int64_t>(), step.data()));
    std::vector<hsize_t> edgesValueDims = {1, 3};
    std::string edgesValueDataset = edgesGroupName + "/value";
    CHECK_HDF5(H5LTmake_dataset(
        fileId, edgesValueDataset.c_str(), 2, edgesValueDims.data(), typeToHDF5<double>(), subdomain.diameter.data()));
    CHECK_HDF5(H5Gclose(edgesGroup));

    CHECK_HDF5(H5LTset_attribute_double(fileId,
                                        groupName.c_str(),
                                        "minCorner",
                                        subdomain.minCorner.data(),
                                        subdomain.minCorner.size()));
    CHECK_HDF5(H5LTset_attribute_double(fileId,
                                        groupName.c_str(),
                                        "maxCorner",
                                        subdomain.maxCorner.data(),
                                        subdomain.maxCorner.size()));
    CHECK_HDF5(H5LTset_attribute_double(fileId,
                                        groupName.c_str(),
                                        "ghostLayerThickness",
                                        subdomain.ghostLayerThickness.data(),
                                        subdomain.ghostLayerThickness.size()));

    CHECK_HDF5(H5Gclose(group));
}

{% for prop in particle %}
void DumpH5MDParallelImpl::write{{prop.name | cap_first}}(hid_t fileId, const data::HostAtoms& atoms)
{
    using Datatype = {{prop.type}};
    constexpr int64_t dimensions = {{prop.dim}};  ///< dimensions of the property

    std::string groupName = "/particles/" + config_.particleGroupName + "/" + config_.{{prop.name}}Dataset;
    auto group = H5Gcreate(fileId, groupName.c_str(), H5P_DEFAULT, H5P_DEFAULT, H5P_DEFAULT);

    std::vector<Datatype> data;
    data.reserve(numLocalParticles * dimensions);
    for (idx_t idx = 0; idx < atoms.numLocalAtoms; ++idx)
    {
        {%- if prop.dim == 1 %}
        data.emplace_back(atoms.get{{prop.name | cap_first}}()(idx));
        {%- else %}
        {%- for i in range(prop.dim) %}
        data.emplace_back(atoms.get{{prop.name | cap_first}}()(idx, {{i}}));
        {%- endfor %}
        {%- endif %}
    }
    MRMD_HOST_CHECK_EQUAL(int64_c(data.size()), numLocalParticles * dimensions);

    std::vector<hsize_t> localDims = {1, uint64_c(numLocalParticles), dimensions};
    std::vector<hsize_t> globalDims = {1, uint64_c(numTotalParticles), dimensions};

    std::string dataset_name = groupName + "/value";
    writeParallel(fileId, dataset_name, globalDims, localDims, data);

    std::vector<hsize_t> dims = {1};
    std::vector<int64_t> step = {0};
    std::vector<double> time = {0};
    std::string stepDataset = groupName + "/step";
    CHECK_HDF5(H5LTmake_dataset(
        fileId, stepDataset.c_str(), 1, dims.data(), typeToHDF5<int64_t>(), step.data()));
    std::string timeDataset = groupName + "/time";
    CHECK_HDF5(H5LTmake_dataset(
        fileId, timeDataset.c_str(), 1, dims.data(), typeToHDF5<double>(), time.data()));
    CHECK_HDF5(H5Gclose(group));
}
{% endfor %}

void DumpH5MDParallelImpl::updateCache(const data::HostAtoms& atoms)
{
    numLocalParticles = atoms.numLocalAtoms;
    MPI_Allreduce(reinterpret_cast<const void*>(&numLocalParticles),
                  reinterpret_cast<void*>(&numTotalParticles),
                  1,
                  MPI_INT64_T,
                  MPI_SUM,
                  config_.mpiInfo->comm);

    MPI_Exscan(&numLocalParticles, &particleOffset, 1, MPI_INT64_T, MPI_SUM, config_.mpiInfo->comm);
    if (config_.mpiInfo->rank == 0) particleOffset = 0;
}

void DumpH5MDParallelImpl::dump(const std::string& filename,
                                const data::Subdomain& subdomain,
                                const data::Atoms& atoms)
{
    data::HostAtoms h_atoms(atoms);  // NOLINT

    updateCache(h_atoms);

    MPI_Info info = MPI_INFO_NULL;

    auto plist = CHECK_HDF5(H5Pcreate(H5P_FILE_ACCESS));
    CHECK_HDF5(H5Pset_fapl_mpio(plist, config_.mpiInfo->comm, info));

    auto file_id = CHECK_HDF5(H5Fcreate(filename.c_str(), H5F_ACC_TRUNC, H5P_DEFAULT, plist));

    auto group1 =
        CHECK_HDF5(H5Gcreate(file_id, "/particles", H5P_DEFAULT, H5P_DEFAULT, H5P_DEFAULT));
    std::string particleGroup = "/particles/" + config_.particleGroupName;
    auto group2 = CHECK_HDF5(
        H5Gcreate(file_id, particleGroup.c_str(), H5P_DEFAULT, H5P_DEFAULT, H5P_DEFAULT));

    writeHeader(file_id);
    writeBox(file_id, subdomain);
    {%- for prop in particle %}
    if (config_.dump{{prop.name | cap_first}}) write{{prop.name | cap_first}}(file_id, h_atoms);
    {%- endfor %}

    CHECK_HDF5(H5Gclose(group1));
    CHECK_HDF5(H5Gclose(group2));

    CHECK_HDF5(H5Fclose(file_id));
}

} // namespace impl

void DumpH5MDParallel::dump(const std::string& filename,
                            const data::Subdomain& subdomain,
                            const data::Atoms& atoms)
{
    impl::DumpH5MDParallelImpl helper(*this);
    helper.dump(filename, subdomain, atoms);
}
#else
void DumpH5MDParallel::dump(const std::string& /*filename*/,
                            const data::Subdomain& /*subdomain*/,
                            const data::Atoms& /*atoms*/)
{
    MRMD_HOST_CHECK(false, "HDF5 Support not available!");
    exit(EXIT_FAILURE);
}
#endif

}  // namespace mrmd::io
